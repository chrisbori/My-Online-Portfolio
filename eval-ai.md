| [Home Page](https://chrisbori.github.io/My-Online-Portfolio/) | [Eval-AI Model Check](https://chrisbori.github.io/My-Online-Portfolio/eval-ai) | [Puerto Rico's Act 22](https://chrisbori.github.io/My-Online-Portfolio/final-project-part-three) | [Visualizing Debt](https://chrisbori.github.io/My-Online-Portfolio/visualizing-government-debt) | [Everybody Poops](https://chrisbori.github.io/My-Online-Portfolio/critique-by-design) |

![EvalAI Logo](https://github.com/user-attachments/assets/ef02be1d-131c-4b2d-b3cf-876a6b9705a7)

# Eval-AI Model Check
**As Team Lead for the Eval-AI project**, I worked alongside four team members for **Bloomberg Government** to apply design thinking principles to a business problem. We designed an open-source compliance evaluation framework for Generative AI models via an [online interface](https://www.figma.com/proto/RscbuGdIkKUeYIRttQDe3y/PIL-Prototype-Design-(FINAL)?node-id=19-2&node-type=canvas&t=v6Gvf3JQeqKgChfB-1&scaling=min-zoom&content-scaling=fixed&page-id=0%3A1&starting-point-node-id=19%3A2) and GitHub benchmark models. The framework aims to mitigate risks like hallucinations and prompt misinterpretations in public interest AI applications by assessing AI systems against U.S. AI regulations and responsible AI principles.

### Check out the [online interface](https://www.figma.com/proto/RscbuGdIkKUeYIRttQDe3y/PIL-Prototype-Design-(FINAL)?node-id=19-2&node-type=canvas&t=v6Gvf3JQeqKgChfB-1&scaling=min-zoom&content-scaling=fixed&page-id=0%3A1&starting-point-node-id=19%3A2)! 

## Problem Statement
**There is too much inconclusiveness around how to properly mitigate the risk of using GenAI for the public interest to ensure proper interpretation and response accuracy.** The underlying issue of this statement is a high risk of hallucinations and prompt misinterpretations in public interest GenAI. 

## Proposed Solution
An online interface that would enable firms to evaluate their GenAI models on national US AI regulations and Responsible AI principles using **benchmark models**. Benchmark models are standardized sets of models/datasets used to evaluate the performance of GenAI across tasks and metrics. They serve as a reference point for comparing models.

![image](https://github.com/user-attachments/assets/0cc32252-9eb5-4233-8e76-85555026d221)

## Introduction
Generative AI, and particularly LLMs, have hit the public and private sectors by storm, entailing a lieu of new security and testing best practices yet to be discovered. Implementing strategies that mitigate the risk of using GenAI solutions offers both a prescriptive and proactive approach to identifying gaps and vulnerabilities in Bloomberg's AI technologies. However, the public interest technology sector does not have a standard/trusted guideline as to how these strategies. Moreover, some firms within the sector may not have the technical acumen/resources to implement such strategies.  

![image](https://github.com/user-attachments/assets/ae022cf9-adb3-4e36-83be-508a30ae11a9)

Using the risk mitigation framework above, our solution focuses on reporting, specifically compliance reporting, within the iterative evaluation process for GenAI. As a result, our solution is one step in the process of mitigating the risks of hallucinations and prompt misinterpretations in GenAI models. However, we also developed a knowledge base of red teaming for GenAI before identifying our final solution. 

## Project Audience

Our primary audience is Bloomberg Gov, however, we want our solution to guide other LLM users of similar functionalities. In this way, our solution will provide a foundation for compliance scoring and reporting that can apply to LLM use cases across different companies and sectors. The larger audience for our solution are firms working with public interest GenAI. 

## Team Roles and Responsibilities

**Team Lead:** Christian Andino Borrero
Own the delivery of the project as a whole. Oversee the project timeline, delegate tasks, and ensure clear communication between team members and stakeholders. Facilitate meetings, set deadlines, and track progress to keep the project on schedule. 

**User Research Lead:** Vashishth Doshi

Own the user research strategy and protocol. Gather insights into user needs, pain points, and expectations from AI systems to ensure red teaming strategies align with user concerns. Analyze feedback and integrate findings into the project deliverables.

**Policy & Compliance Specialist:** Lisa Menda

Research relevant regulations and compliance requirements for the use of Bloomberg Gov LLM. Ensure the testing methods are consistent with both internal policies and external regulations.

**GenAI/LLM Test Designer:** Grace Sam

Own the design of LLM/GenAI testing method. Identify potential weaknesses in AI systems and outline tests that reveal these vulnerabilities. Develop protocols for assessing and improving system resilience to various threats. Focus on strategies to protect user data during testing and in production as well as identifying/preventing biases in AI outputs, particularly discriminatory or offensive responses. Identify privacy risks and help develop red teaming techniques to safeguard sensitive information. Ensure compliance with data privacy laws and guidelines in all test scenarios and provide input on data handling protocols.

**Data Security & Ethics Specialist:** Zachary Zwijacz

Focus on strategies to protect user data during testing and in production as well as identifying/preventing biases in AI outputs, particularly discriminatory or offensive responses. Identify privacy risks and help develop red teaming techniques to safeguard sensitive information. Ensure compliance with data privacy laws and guidelines in all test scenarios and provide input on data handling protocols.

## Sprint Structure

![image](https://github.com/user-attachments/assets/a0414205-1cf4-4416-9223-f61b8ebd35c4)

| [Home Page](https://chrisbori.github.io/My-Online-Portfolio/) | [Eval-AI Model Check](https://chrisbori.github.io/My-Online-Portfolio/eval-ai) | [Puerto Rico's Act 22](https://chrisbori.github.io/My-Online-Portfolio/final-project-part-three) | [Visualizing Debt](https://chrisbori.github.io/My-Online-Portfolio/visualizing-government-debt) | [Everybody Poops](https://chrisbori.github.io/My-Online-Portfolio/critique-by-design) |
